import requests
from data.data_manager import insert_news
from config import SYMBOLS
from datetime import datetime, timedelta
import re
from ai.news_sentiment_ai import analyze_sentiment
import mysql.connector
from config import MYSQL_CONFIG

API_KEY = "da4aff9ddef8f6534f149d3803e2e0420958c5f4"

def fetch_news():
    print("ğŸ“° Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø±...")
    # ÙÙ‚Ø· Ø§Ø®Ø¨Ø§Ø± Û· Ø±ÙˆØ² Ø§Ø®ÛŒØ± Ø±Ùˆ Ø¨Ú¯ÛŒØ±
    since_date = (datetime.utcnow() - timedelta(days=7)).strftime('%Y-%m-%d')
    url = f"https://cryptopanic.com/api/v1/posts/?auth_token={API_KEY}&public=true&kind=news&published_since={since_date}"

    try:
        response = requests.get(url)
        data = response.json()
        print(f"Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡: {data['results']}")
        
        if "results" not in data:
            print("âš ï¸ Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return

        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        conn = mysql.connector.connect(**MYSQL_CONFIG)
        cursor = conn.cursor()

        for item in data["results"]:
            title = item.get("title", "")
            content = item.get("content", title)
            if not title:
                continue

            source = item.get("domain", "unknown")
            published_at = item.get("published_at", datetime.utcnow().isoformat())
            # ØªØ¨Ø¯ÛŒÙ„ published_at Ø¨Ù‡ ÙØ±Ù…Øª datetime
            published_at_dt = datetime.strptime(published_at, '%Y-%m-%dT%H:%M:%S%z')

            # Ú†Ú© Ú©Ø±Ø¯Ù† Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ
            check_query = """
            SELECT COUNT(*) FROM news
            WHERE symbol = %s AND title = %s AND published_at = %s
            """
            for symbol in SYMBOLS:
                pattern = r'\b' + re.escape(symbol.replace("USDT", "").upper()) + r'\b'
                if re.search(pattern, title.upper()):
                    cursor.execute(check_query, (symbol, title, published_at))
                    result = cursor.fetchone()
                    if result[0] > 0:  # Ø§Ú¯Ù‡ Ø®Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
                        print(f"âš ï¸ Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} - {title[:40]}...")
                        continue

                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ sentiment_score
                    sentiment_score = 0.0
                    if content and content.strip():
                        sentiment_score = analyze_sentiment(content)
                    else:
                        print(f"âš ï¸ Ù…Ø­ØªÙˆØ§ ÛŒØ§ Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ø¨Ø±: {title}")

                    # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø¨Ø±
                    insert_news(symbol, title, source, published_at_dt, content, None)

                    # ÙÛŒÙ„ØªØ± Ø§Ø®Ø¨Ø§Ø± Ù…Ù‡Ù…
                    important_keywords = ['partnership', 'regulation', 'adoption', 'upgrade', 'halving']
                    is_important = any(keyword in title.lower() for keyword in important_keywords)
                    print(f"âœ… Ø®Ø¨Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ {symbol} - {title[:40]}... {'(Ù…Ù‡Ù…)' if is_important else ''}")

        conn.commit()

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø±: {e}")
    finally:
        if 'conn' in locals() and conn.is_connected():
            cursor.close()
            conn.close()

if __name__ == "__main__":
    fetch_news()